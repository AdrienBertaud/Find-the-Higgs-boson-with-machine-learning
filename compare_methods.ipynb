{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from implementations import *\n",
    "from split_data import *\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = 'data/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "\n",
    "# Standardize data\n",
    "tX = standardize(tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 30)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = split_data(tX, y, 0.8)\n",
    "best_models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear regression using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "least_squares_GD // Parameters: max_iter=10 gamma=0.01 // Time: 0.107227s // train loss: 0.46525219398362894 // test loss: 0.46507146646928105\n",
      "least_squares_GD // Parameters: max_iter=10 gamma=0.049 // Time: 0.095504s // train loss: 0.42870207570134317 // test loss: 0.4289706313558528\n",
      "least_squares_GD // Parameters: max_iter=10 gamma=0.05 // Time: 0.076589s // train loss: 0.4282770800415848 // test loss: 0.42855451671850586\n",
      "least_squares_GD // Parameters: max_iter=10 gamma=0.053 // Time: 0.090288s // train loss: 0.4270785184578131 // test loss: 0.4273812324402966\n",
      "least_squares_GD // Parameters: max_iter=10 gamma=0.07 // Time: 0.080551s // train loss: 0.4219540905759663 // test loss: 0.4223677224896806\n",
      "least_squares_GD // Parameters: max_iter=10 gamma=0.1 // Time: 0.073266s // train loss: 0.4167555868631728 // test loss: 0.4172784113974019\n",
      "least_squares_GD // Parameters: max_iter=100 gamma=0.01 // Time: 0.841558s // train loss: 0.41721107910194555 // test loss: 0.41771055262636425\n",
      "least_squares_GD // Parameters: max_iter=100 gamma=0.049 // Time: 0.69691s // train loss: 0.39899972075443796 // test loss: 0.39969790335100996\n",
      "least_squares_GD // Parameters: max_iter=100 gamma=0.05 // Time: 0.69385s // train loss: 0.3987838539784226 // test loss: 0.39948206088489485\n",
      "least_squares_GD // Parameters: max_iter=100 gamma=0.053 // Time: 0.699843s // train loss: 0.39816842007181247 // test loss: 0.3988662700708106\n",
      "least_squares_GD // Parameters: max_iter=100 gamma=0.07 // Time: 0.750844s // train loss: 0.39542531193843544 // test loss: 0.39611387693404654\n",
      "least_squares_GD // Parameters: max_iter=100 gamma=0.1 // Time: 0.698955s // train loss: 0.3925930461858477 // test loss: 0.3932601383256776\n",
      "least_squares_GD // Parameters: max_iter=500 gamma=0.01 // Time: 3.620977s // train loss: 0.39881119733072806 // test loss: 0.39950915615625154\n",
      "least_squares_GD // Parameters: max_iter=500 gamma=0.049 // Time: 3.481131s // train loss: 0.3896020469978158 // test loss: 0.3902452516060408\n",
      "least_squares_GD // Parameters: max_iter=500 gamma=0.05 // Time: 3.446207s // train loss: 0.38958495395782744 // test loss: 0.3902282585111619\n",
      "least_squares_GD // Parameters: max_iter=500 gamma=0.053 // Time: 3.390444s // train loss: 0.3895423817050375 // test loss: 0.39018604169051413\n",
      "least_squares_GD // Parameters: max_iter=500 gamma=0.07 // Time: 3.495377s // train loss: 0.3894374166877129 // test loss: 0.39008328579089496\n",
      "least_squares_GD // Parameters: max_iter=500 gamma=0.1 // Time: 3.455702s // train loss: 0.38941027636407505 // test loss: 0.39005750215785245\n",
      "least_squares_GD // Parameters: max_iter=750 gamma=0.01 // Time: 5.117439s // train loss: 0.394841725918405 // test loss: 0.3955267321299062\n",
      "least_squares_GD // Parameters: max_iter=750 gamma=0.049 // Time: 5.069471s // train loss: 0.38942985619197557 // test loss: 0.3900760554292746\n",
      "least_squares_GD // Parameters: max_iter=750 gamma=0.05 // Time: 5.121551s // train loss: 0.389427208307447 // test loss: 0.39007353718774956\n",
      "least_squares_GD // Parameters: max_iter=750 gamma=0.053 // Time: 5.310555s // train loss: 0.3894210796610576 // test loss: 0.3900677379452974\n",
      "least_squares_GD // Parameters: max_iter=750 gamma=0.07 // Time: 6.03812s // train loss: 0.38940945497883356 // test loss: 0.3900566417296976\n",
      "least_squares_GD // Parameters: max_iter=750 gamma=0.1 // Time: 6.145242s // train loss: 0.3894073054716296 // test loss: 0.39005324487104825\n",
      "least_squares_GD // Parameters: max_iter=1000 gamma=0.01 // Time: 6.974738s // train loss: 0.3926256641820254 // test loss: 0.3932931999545118\n",
      "least_squares_GD // Parameters: max_iter=1000 gamma=0.049 // Time: 7.611914s // train loss: 0.3894107572113627 // test loss: 0.3900579700576558\n",
      "least_squares_GD // Parameters: max_iter=1000 gamma=0.05 // Time: 7.742468s // train loss: 0.3894103152377387 // test loss: 0.39005752972347074\n",
      "least_squares_GD // Parameters: max_iter=1000 gamma=0.053 // Time: 7.172233s // train loss: 0.38940932875854817 // test loss: 0.390056500826549\n",
      "least_squares_GD // Parameters: max_iter=1000 gamma=0.07 // Time: 7.073307s // train loss: 0.3894074843999885 // test loss: 0.39005374601972065\n",
      "least_squares_GD // Parameters: max_iter=1000 gamma=0.1 // Time: 7.328227s // train loss: 0.38940680598879773 // test loss: 0.39005148551081215\n",
      "least_squares_GD // Parameters: max_iter=1500 gamma=0.01 // Time: 10.320484s // train loss: 0.3905897284699459 // test loss: 0.3912380398063508\n",
      "least_squares_GD // Parameters: max_iter=1500 gamma=0.049 // Time: 10.49189s // train loss: 0.3894073549755611 // test loss: 0.39005339078663936\n",
      "least_squares_GD // Parameters: max_iter=1500 gamma=0.05 // Time: 10.21749s // train loss: 0.38940730701837284 // test loss: 0.39005324767376853\n",
      "least_squares_GD // Parameters: max_iter=1500 gamma=0.053 // Time: 10.618918s // train loss: 0.3894071834933507 // test loss: 0.3900528486804729\n",
      "least_squares_GD // Parameters: max_iter=1500 gamma=0.07 // Time: 10.168006s // train loss: 0.38940673443512397 // test loss: 0.39005124414800624\n",
      "least_squares_GD // Parameters: max_iter=1500 gamma=0.1 // Time: 10.502007s // train loss: 0.3894061717097933 // test loss: 0.3900498812031061\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "max_iters = [10, 100, 500, 750, 1000, 1500]\n",
    "gammas = [0.01, 0.049, 0.05, 0.053, 0.07, 0.1]\n",
    "\n",
    "best_models['least_squares_GD'] = {\n",
    "    'loss_test': 1\n",
    "}\n",
    "\n",
    "for max_iter in max_iters:\n",
    "    for gamma in gammas:\n",
    "        # Gradient descent\n",
    "        start_time = datetime.datetime.now()\n",
    "        w_initial = np.array(np.zeros(30))\n",
    "        w, loss_train = least_squares_GD(y_train, x_train, w_initial, max_iter, gamma)\n",
    "        loss_test = compute_loss(y_test, x_test, w)\n",
    "        end_time = datetime.datetime.now()\n",
    "        print('least_squares_GD // Parameters: ', end = '')\n",
    "        print('max_iter=' + str(max_iter) + \" gamma=\" + str(gamma), end = '')\n",
    "        print(' // Time: ' + str((end_time - start_time).total_seconds()) + 's', end = '')\n",
    "        print(\" // train loss: \" + str(loss_train), end = '')\n",
    "        print(\" // test loss: \" + str(loss_test))\n",
    "        if best_models['least_squares_GD']['loss_test'] > loss_test:\n",
    "            best_models['least_squares_GD']['loss_test'] = loss_test\n",
    "            best_models['least_squares_GD']['gamma'] = gamma\n",
    "            best_models['least_squares_GD']['max_iter'] = max_iter\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Linear regression using stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "least_squares_SGD // Parameters: max_iter=10 gamma=0.01 // Time: 0.309497s // train loss: 0.5379058738737937 // test loss: 0.5381510089686146\n",
      "least_squares_SGD // Parameters: max_iter=10 gamma=0.049 // Time: 0.248851s // train loss: 0.5545475172340977 // test loss: 0.553866630107197\n",
      "least_squares_SGD // Parameters: max_iter=10 gamma=0.05 // Time: 0.253265s // train loss: 0.5778756220924579 // test loss: 0.5776464081315242\n",
      "least_squares_SGD // Parameters: max_iter=10 gamma=0.053 // Time: 0.259537s // train loss: 0.6605660692294563 // test loss: 0.6561251330424567\n",
      "least_squares_SGD // Parameters: max_iter=10 gamma=0.07 // Time: 0.242904s // train loss: 0.5992502810492313 // test loss: 0.6019676591871684\n",
      "least_squares_SGD // Parameters: max_iter=10 gamma=0.1 // Time: 0.241919s // train loss: 0.8964452744868399 // test loss: 0.894060292433458\n",
      "least_squares_SGD // Parameters: max_iter=100 gamma=0.01 // Time: 2.488692s // train loss: 0.45026175730933005 // test loss: 0.4507196317336612\n",
      "least_squares_SGD // Parameters: max_iter=100 gamma=0.049 // Time: 2.325482s // train loss: 0.5003033872148753 // test loss: 0.4994926625534178\n",
      "least_squares_SGD // Parameters: max_iter=100 gamma=0.05 // Time: 2.32808s // train loss: 4.70091199561528 // test loss: 4.681530790414803\n",
      "least_squares_SGD // Parameters: max_iter=100 gamma=0.053 // Time: 2.347645s // train loss: 5.854791975999961 // test loss: 5.77619254940765\n",
      "least_squares_SGD // Parameters: max_iter=100 gamma=0.07 // Time: 2.329042s // train loss: 1.2583462440977824 // test loss: 1.2498866119392598\n",
      "least_squares_SGD // Parameters: max_iter=100 gamma=0.1 // Time: 2.351108s // train loss: 5164.75692074732 // test loss: 5149.5250313584465\n",
      "least_squares_SGD // Parameters: max_iter=500 gamma=0.01 // Time: 11.606255s // train loss: 0.4241319714419552 // test loss: 0.42461227957781167\n",
      "least_squares_SGD // Parameters: max_iter=500 gamma=0.049 // Time: 11.620449s // train loss: 0.7237029706074224 // test loss: 0.7217797769690663\n",
      "least_squares_SGD // Parameters: max_iter=500 gamma=0.05 // Time: 12.004607s // train loss: 0.5242714976302133 // test loss: 0.5259431358216785\n",
      "least_squares_SGD // Parameters: max_iter=500 gamma=0.053 // Time: 12.549107s // train loss: 0.7654284400289356 // test loss: 0.7698530845275976\n",
      "least_squares_SGD // Parameters: max_iter=500 gamma=0.07 // Time: 12.454698s // train loss: 3.0553482276334742 // test loss: 3.0488676332912816\n",
      "least_squares_SGD // Parameters: max_iter=500 gamma=0.1 // Time: 11.586452s // train loss: 140500.01200349012 // test loss: 138660.92040046462\n",
      "least_squares_SGD // Parameters: max_iter=750 gamma=0.01 // Time: 17.388994s // train loss: 0.41225872890916104 // test loss: 0.4118808904074376\n",
      "least_squares_SGD // Parameters: max_iter=750 gamma=0.049 // Time: 17.510314s // train loss: 1.2737129519524493 // test loss: 1.2715472316432064\n",
      "least_squares_SGD // Parameters: max_iter=750 gamma=0.05 // Time: 17.959384s // train loss: 0.9981995117806601 // test loss: 1.006895429316646\n",
      "least_squares_SGD // Parameters: max_iter=750 gamma=0.053 // Time: 19.067565s // train loss: 2.4235197214798045 // test loss: 2.38303409652103\n",
      "least_squares_SGD // Parameters: max_iter=750 gamma=0.07 // Time: 18.274734s // train loss: 1.4108502352817194 // test loss: 1.4028609037152477\n",
      "least_squares_SGD // Parameters: max_iter=750 gamma=0.1 // Time: 17.430655s // train loss: 263924776.8980226 // test loss: 263792322.90298572\n",
      "least_squares_SGD // Parameters: max_iter=1000 gamma=0.01 // Time: 23.241779s // train loss: 0.4574903375089425 // test loss: 0.45854423613449147\n",
      "least_squares_SGD // Parameters: max_iter=1000 gamma=0.049 // Time: 23.239684s // train loss: 0.634614974819439 // test loss: 0.6357505808036782\n",
      "least_squares_SGD // Parameters: max_iter=1000 gamma=0.05 // Time: 23.214519s // train loss: 1.7626764627733773 // test loss: 1.758426483297032\n",
      "least_squares_SGD // Parameters: max_iter=1000 gamma=0.053 // Time: 23.187863s // train loss: 0.5314309985686224 // test loss: 0.5306528871141413\n",
      "least_squares_SGD // Parameters: max_iter=1000 gamma=0.07 // Time: 23.201963s // train loss: 142.77890440865212 // test loss: 140.58725931571672\n",
      "least_squares_SGD // Parameters: max_iter=1000 gamma=0.1 // Time: 23.17651s // train loss: 6.640662021491437e+16 // test loss: 6.763844540200061e+16\n",
      "least_squares_SGD // Parameters: max_iter=1500 gamma=0.01 // Time: 34.982542s // train loss: 0.40975289124560155 // test loss: 0.4101885724806808\n",
      "least_squares_SGD // Parameters: max_iter=1500 gamma=0.049 // Time: 37.450873s // train loss: 0.5558474802761987 // test loss: 0.5483723096850199\n",
      "least_squares_SGD // Parameters: max_iter=1500 gamma=0.05 // Time: 37.717695s // train loss: 0.534470924927472 // test loss: 0.535446078689697\n",
      "least_squares_SGD // Parameters: max_iter=1500 gamma=0.053 // Time: 36.237343s // train loss: 0.8372866303225093 // test loss: 0.839332045048169\n",
      "least_squares_SGD // Parameters: max_iter=1500 gamma=0.07 // Time: 37.925865s // train loss: 9.62896477540697 // test loss: 9.704247369004253\n",
      "least_squares_SGD // Parameters: max_iter=1500 gamma=0.1 // Time: 37.039077s // train loss: 6.835894513944034e+23 // test loss: 6.820227068676151e+23\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "max_iters = [10, 100, 500, 750, 1000, 1500]\n",
    "gammas = [0.01, 0.049, 0.05, 0.053, 0.07, 0.1]\n",
    "\n",
    "best_models['least_squares_SGD'] = {\n",
    "    'loss_test': 1\n",
    "}\n",
    "\n",
    "for max_iter in max_iters:\n",
    "    for gamma in gammas:\n",
    "        # Gradient descent\n",
    "        start_time = datetime.datetime.now()\n",
    "        w_initial = np.array(np.zeros(30))\n",
    "        w, loss_train = least_squares_SGD(y_train, x_train, w_initial, max_iter, gamma)\n",
    "        loss_test = compute_loss(y_test, x_test, w)\n",
    "        end_time = datetime.datetime.now()\n",
    "        print('least_squares_SGD // Parameters: ', end = '')\n",
    "        print('max_iter=' + str(max_iter) + \" gamma=\" + str(gamma), end = '')\n",
    "        print(' // Time: ' + str((end_time - start_time).total_seconds()) + 's', end = '')\n",
    "        print(\" // train loss: \" + str(loss_train), end = '')\n",
    "        print(\" // test loss: \" + str(loss_test))\n",
    "        if best_models['least_squares_SGD']['loss_test'] > loss_test:\n",
    "            best_models['least_squares_SGD']['loss_test'] = loss_test\n",
    "            best_models['least_squares_SGD']['gamma'] = gamma\n",
    "            best_models['least_squares_SGD']['max_iter'] = max_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "least_squares_GD\n",
      "{'loss_test': 0.3900498812031061, 'gamma': 0.1, 'max_iter': 1500}\n",
      "\n",
      "least_squares_SGD\n",
      "{'loss_test': 0.4101885724806808, 'gamma': 0.01, 'max_iter': 1500}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in best_models:\n",
    "    print(model)\n",
    "    print(best_models[model])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
