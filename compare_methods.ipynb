{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from implementations import *\n",
    "from evaluation import *\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = 'data/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "\n",
    "# Standardize data\n",
    "tX = standardize(tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 30)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = split_data(tX, y, 0.8)\n",
    "best_models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear regression using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "least_squares_GD // Parameters: max_iter=100 gamma=0.1 // Time: 0.749193s // train loss: 0.3925930461858477 // test loss: 0.3932601383256776\n",
      "acc: 0.71208\n",
      "f1: 0.6624302396473292\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "#max_iters = [10, 100, 500, 750, 1000, 1500]\n",
    "#gammas = [0.01, 0.049, 0.05, 0.053, 0.07, 0.1]\n",
    "max_iters = [100]\n",
    "gammas = [0.1]\n",
    "\n",
    "best_models['least_squares_GD'] = {\n",
    "    'loss_test': 1000000\n",
    "}\n",
    "\n",
    "for max_iter in max_iters:\n",
    "    for gamma in gammas:\n",
    "        # Gradient descent\n",
    "        start_time = datetime.datetime.now()\n",
    "        w_initial = np.array(np.zeros(30))\n",
    "        w, loss_train = least_squares_GD(y_train, x_train, w_initial, max_iter, gamma)\n",
    "        loss_test = compute_loss(y_test, x_test, w)\n",
    "        end_time = datetime.datetime.now()\n",
    "        print('least_squares_GD // Parameters: ', end = '')\n",
    "        print('max_iter=' + str(max_iter) + \" gamma=\" + str(gamma), end = '')\n",
    "        print(' // Time: ' + str((end_time - start_time).total_seconds()) + 's', end = '')\n",
    "        print(\" // train loss: \" + str(loss_train), end = '')\n",
    "        print(\" // test loss: \" + str(loss_test))\n",
    "        print(\"acc: \" + str(calculate_accuracy(w, x_test, y_test)))\n",
    "        print(\"f1: \" + str(calculate_f1_score(w, x_test, y_test)))\n",
    "        if best_models['least_squares_GD']['loss_test'] > loss_test:\n",
    "            best_models['least_squares_GD']['loss_test'] = loss_test\n",
    "            best_models['least_squares_GD']['gamma'] = gamma\n",
    "            best_models['least_squares_GD']['max_iter'] = max_iter\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Linear regression using stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "least_squares_SGD // Parameters: max_iter=100 gamma=0.1 // Time: 2.393599s // train loss: 1238.7773879450865 // test loss: 1229.9949166567849\n",
      "acc: 0.51104\n",
      "f1: 0.4033289403036071\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "#max_iters = [10, 100, 500, 750, 1000, 1500]\n",
    "#gammas = [0.01, 0.049, 0.05, 0.053, 0.07, 0.1]\n",
    "max_iters = [100]\n",
    "gammas = [0.1]\n",
    "\n",
    "best_models['least_squares_SGD'] = {\n",
    "    'loss_test': 1000000\n",
    "}\n",
    "\n",
    "for max_iter in max_iters:\n",
    "    for gamma in gammas:\n",
    "        # Gradient descent\n",
    "        start_time = datetime.datetime.now()\n",
    "        w_initial = np.array(np.zeros(30))\n",
    "        w, loss_train = least_squares_SGD(y_train, x_train, w_initial, max_iter, gamma)\n",
    "        loss_test = compute_loss(y_test, x_test, w)\n",
    "        end_time = datetime.datetime.now()\n",
    "        print('least_squares_SGD // Parameters: ', end = '')\n",
    "        print('max_iter=' + str(max_iter) + \" gamma=\" + str(gamma), end = '')\n",
    "        print(' // Time: ' + str((end_time - start_time).total_seconds()) + 's', end = '')\n",
    "        print(\" // train loss: \" + str(loss_train), end = '')\n",
    "        print(\" // test loss: \" + str(loss_test))\n",
    "        print(\"acc: \" + str(calculate_accuracy(w, x_test, y_test)))\n",
    "        print(\"f1: \" + str(calculate_f1_score(w, x_test, y_test)))\n",
    "        if best_models['least_squares_SGD']['loss_test'] > loss_test:\n",
    "            best_models['least_squares_SGD']['loss_test'] = loss_test\n",
    "            best_models['least_squares_SGD']['gamma'] = gamma\n",
    "            best_models['least_squares_SGD']['max_iter'] = max_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "least_squares_GD\n",
      "{'loss_test': 0.3932601383256776, 'gamma': 0.1, 'max_iter': 100}\n",
      "\n",
      "least_squares_SGD\n",
      "{'loss_test': 1229.9949166567849, 'gamma': 0.1, 'max_iter': 100}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in best_models:\n",
    "    print(model)\n",
    "    print(best_models[model])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
